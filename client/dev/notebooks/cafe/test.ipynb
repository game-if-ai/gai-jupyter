{
 "cells": [
   {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "contenteditable": false,
    "deletable": false,
    "editable": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "contenteditable": false,
    "deletable": false,
    "editable": false,
    "gai_cell_type": "SETUP",
    "gai_title": "Setup",
    "gai_description": "This is the setup cell. It will generate the testing and training data for your model.",
    "tags": [
     "highlight"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk, json\n",
    "from IPython.display import JSON\n",
    "\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "REVIEW = \"review\"\n",
    "\n",
    "# use smaller set\n",
    "with open(\"cafe/reviews.json\") as IN:\n",
    "    data = pd.DataFrame(json.load(IN))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[REVIEW],\n",
    "                                                    data['rating'],\n",
    "                                                    stratify=data['rating'],\n",
    "                                                    random_state=21)\n",
    "\n",
    "JSON([len(x_train) + len(y_train), len(x_test) + len(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "gai_cell_type": "MODEL",
    "gai_title": "Model",
    "gai_description": "This is the model cell. It has been filled in with stub code that you should edit.",
    "check_lint": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# TODO: preprocess data?\n",
    "\n",
    "# pick vectorizer\n",
    "vectorizer = HashingVectorizer()\n",
    "x_train_features = vectorizer.fit_transform(x_train)\n",
    "x_test_features = vectorizer.transform(x_test)\n",
    "\n",
    "def train(classifier, x, y):\n",
    "    classifier.fit(x, y)\n",
    "\n",
    "# pick classifier\n",
    "classifier = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "# train\n",
    "train(classifier,x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "gai_cell_type": "LINT",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%pycodestyle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# TODO: preprocess data?\n",
    "\n",
    "# pick vectorizer\n",
    "vectorizer = HashingVectorizer()\n",
    "x_train_features = vectorizer.fit_transform(x_train)\n",
    "x_test_features = vectorizer.transform(x_test)\n",
    "\n",
    "def train(classifier, x, y):\n",
    "    classifier.fit(x, y)\n",
    "\n",
    "# pick classifier\n",
    "classifier = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "# train\n",
    "train(classifier,x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "contenteditable": false,
    "deletable": false,
    "editable": false,
    "gai_cell_type": "VALIDATION",
    "gai_title": "Validation",
    "gai_description": "This is the validation cell. It will use the testing data to generate outputs from your model.",
    "tags": [
     "highlight"
    ]
   },
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(x_test_features)\n",
    "y_proba = classifier.predict_proba(x_test_features)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import JSON\n",
    "output = []\n",
    "x_test_list = x_test.to_list()\n",
    "y_test_list = y_test.to_list()\n",
    "experiment_size = y_pred_test.size // 5\n",
    "trial = 0\n",
    "experiment = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "f1_scores = []\n",
    "for i in range(y_pred_test.size):\n",
    "    if trial == experiment_size and i + experiment_size <= y_pred_test.size:\n",
    "        output.append(experiment)\n",
    "        experiment = []\n",
    "        trial = 0\n",
    "        f1_scores.append(f1_score(y_true, y_pred))\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "    y_true.append(y_test_list[i])\n",
    "    y_pred.append(y_pred_test[i])\n",
    "    experiment.append({\n",
    "        \"inputText\": x_test_list[i],\n",
    "        \"realLabel\": y_test_list[i],\n",
    "        \"classifierLabel\": y_pred_test[i],\n",
    "        \"confidence\": max(y_proba[i])\n",
    "    })\n",
    "    trial += 1\n",
    "\n",
    "JSON(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b655b960f58f067faa17677b2a61dad4dd7349f9b1d9b48ec4c1e58710c42f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}